{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dNP5qbfkrLb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AWS Lambda**"
      ],
      "metadata": {
        "id": "v8Y69mUPkw0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "s3 = boto3.client('s3')\n",
        "\n",
        "def lambda_handler(event, context):\n",
        "bucket = event['Records'][0]['s3']['bucket']['name']\n",
        "key = event['Records'][0]['s3']['object']['key']\n",
        "\n",
        "# Read the CSV file from S3\n",
        "response = s3.get_object(Bucket=bucket, Key=key)\n",
        "df = pd.read_csv(response['Body'], encoding='utf-8')\n",
        "\n",
        "# Ensure 'delay' column exists\n",
        "if 'delay' not in df.columns:\n",
        "return {\"status\": \"error\", \"message\": \"Column 'delay' not found in dataset.\"}\n",
        "\n",
        "# Detect anomalies (Flights delayed over 500 minutes)\n",
        "anomalies = df[df['delay'] > 500]\n",
        "clean_data = df[df['delay'] <= 500]\n",
        "\n",
        "# Move anomalies to the 'anomalies' folder\n",
        "if not anomalies.empty:\n",
        "buffer = io.StringIO()\n",
        "anomalies.to_csv(buffer, index=False)\n",
        "anomaly_key = key.replace(\"raw\", \"anomalies\")  # Ensure correct folder structure\n",
        "s3.put_object(Bucket=bucket, Key=anomaly_key, Body=buffer.getvalue())\n",
        "\n",
        "# Move clean data to 'processed' instead of overwriting 'raw'\n",
        "if not clean_data.empty:\n",
        "buffer = io.StringIO()\n",
        "clean_data.to_csv(buffer, index=False)\n",
        "processed_key = key.replace(\"raw\", \"processed\")  # Store cleaned data in /processed/\n",
        "s3.put_object(Bucket=bucket, Key=processed_key, Body=buffer.getvalue())\n",
        "\n",
        "return {\"status\": \"processed\", \"clean_records\": len(clean_data), \"anomaly_records\": len(anomalies)}\n"
      ],
      "metadata": {
        "id": "LOEXAakgk3-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creation of state machine**"
      ],
      "metadata": {
        "id": "SbZukRihk7N2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "\"StartAt\": \"RunCrawler\",\n",
        "\"States\": {\n",
        "\"RunCrawler\": {\n",
        "\"Type\": \"Task\",\n",
        "\"Resource\": \"arn:aws:states:::aws-sdk:glue:startCrawler\",\n",
        "\"Parameters\": {\n",
        "\"Name\": \"AirlineRawDataCrawler\"\n",
        "},\n",
        "\"Next\": \"WaitForCrawler\"\n",
        "},\n",
        "\"WaitForCrawler\": {\n",
        "\"Type\": \"Wait\",\n",
        "\"Seconds\": 60,\n",
        "\"Next\": \"CheckCrawlerStatus\"\n",
        "},\n",
        "\"CheckCrawlerStatus\": {\n",
        "\"Type\": \"Task\",\n",
        "\"Resource\": \"arn:aws:states:::aws-sdk:glue:getCrawler\",\n",
        "\"Parameters\": {\n",
        "\"Name\": \"AirlineRawDataCrawler\"\n",
        "},\n",
        "\"Next\": \"CrawlerStatusChoice\"\n",
        "},\n",
        "\"CrawlerStatusChoice\": {\n",
        "\"Type\": \"Choice\",\n",
        "\"Choices\": [\n",
        "{\n",
        "\"Variable\": \"$.Crawler.State\",\n",
        "\"StringEquals\": \"READY\",\n",
        "\"Next\": \"RunGlueJob\"\n",
        "}\n",
        "],\n",
        "\"Default\": \"WaitForCrawler\"\n",
        "},\n",
        "\"RunGlueJob\": {\n",
        "\"Type\": \"Task\",\n",
        "\"Resource\": \"arn:aws:states:::glue:startJobRun.sync\",\n",
        "\"Parameters\": {\n",
        "\"JobName\": \"AirlineTransformJob\"\n",
        "},\n",
        "\"Next\": \"Success\",\n",
        "\"Catch\": [\n",
        "{\n",
        "\"ErrorEquals\": [\n",
        "\"States.ALL\"\n",
        "],\n",
        "\"Next\": \"SendSNSAlert\"\n",
        "}\n",
        "]\n",
        "},\n",
        "\"SendSNSAlert\": {\n",
        "\"Type\": \"Task\",\n",
        "\"Resource\": \"arn:aws:states:::sns:publish\",\n",
        "\"Parameters\": {\n",
        "\"TopicArn\": \"arn:aws:sns:us-east-1:891612582976:AirlineDataFailureTopic\",\n",
        "\"Message\": \"Airline data pipeline failed. Check logs.\",\n",
        "\"Subject\": \"Airline Pipeline Failure\"\n",
        "},\n",
        "\"Next\": \"Fail\"\n",
        "},\n",
        "\"Success\": {\n",
        "\"Type\": \"Succeed\"\n",
        "},\n",
        "\"Fail\": {\n",
        "\"Type\": \"Fail\"\n",
        "}\n",
        "}\n",
        "}\n"
      ],
      "metadata": {
        "id": "wyYP_yoUk_Ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Event bridge**"
      ],
      "metadata": {
        "id": "YkdS1oZblCBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "\"source\": [\"aws.s3\"],\n",
        "\"detail-type\": [\"Object Created\"],\n",
        "\"detail\": {\n",
        "\"bucket\": {\n",
        "\"name\": [\"airline-data-bucket-cc\"]\n",
        "},\n",
        "\"object\": {\n",
        "\"key\": [{\n",
        "\"prefix\": \"raw/\"\n",
        "}]\n",
        "}\n",
        "}\n",
        "}"
      ],
      "metadata": {
        "id": "15Q_jFaXlGtl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}